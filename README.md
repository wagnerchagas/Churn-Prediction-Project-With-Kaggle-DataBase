## üß† Projeto de Previs√£o de Churn em Telecomunica√ß√µes

**Recursos**:

* **Dashboard Streamlit**: [https://churn-prediction-project-with-kaggle-database-g5q9uswffyie7tzb.streamlit.app/](https://churn-prediction-project-with-kaggle-database-g5q9uswffyie7tzb.streamlit.app/)
* **Imagens**: pasta ‚Äúprints do funcionamento‚Äù com capturas das funcionalidades, em est√°gio inicial e final.

---

## üìâ 1. Introdu√ß√£o

Este projeto teve como objetivo prever o churn de clientes de uma operadora de telecomunica√ß√µes, utilizando o conjunto de dados **Telco Customer Churn** (Kaggle). Atrav√©s de t√©cnicas de aprendizado de m√°quina e an√°lise explorat√≥ria, concentrei meus esfor√ßos em identificar os principais fatores que influenciam a sa√≠da dos clientes, desenvolver um modelo preditivo eficaz e propor estrat√©gias de reten√ß√£o baseadas em perfis de risco. Al√©m disso, incorporei uma an√°lise de custo-benef√≠cio para apoiar a tomada de decis√£o orientada por dados.

**Origem dos Dados**: Telco Customer Churn (Kaggle)
**T√©cnicas Principais**:

1. **Random Forest** ‚Äî escolhi por sua robustez e facilidade de interpreta√ß√£o via import√¢ncia de atributos.
2. **SMOTETomek (SMOTE + Tomek Links)** ‚Äî gerei amostras sint√©ticas da classe minorit√°ria (SMOTE) e removi pares de pontos amb√≠guos na fronteira de decis√£o (Tomek Links).
3. **Engenharia de Features Avan√ßada** ‚Äî criei vari√°veis a partir de padr√µes apontados pela an√°lise de erros (e.g., `tenure_group`, `high_value_flag`, `SeniorContractCombo`, `SupportServicesCount`).
4. **Otimiza√ß√£o de Threshold via F‚ÇÇ-Score** ‚Äî priorizei o recall (capturar churners) em rela√ß√£o √† precis√£o.
5. **Pr√©-processamento e Pipeline Unificado** ‚Äî utilizei `ColumnTransformer` para imputa√ß√£o e escala das vari√°veis num√©ricas, e codifica√ß√£o das categ√≥ricas, tudo encadeado em um √∫nico pipeline sem vazamento de dados.
6. **Hyperparameter Tuning com RandomizedSearchCV** ‚Äî realizei busca aleat√≥ria em um espa√ßo de par√¢metros (e.g., `n_estimators`, `max_depth`, `class_weight`, `smote__sampling_strategy`) usando `make_scorer(fbeta_score, beta=2)` para otimizar o F‚ÇÇ‚ÄëScore.

---

## üéØ 2. Objetivo do Projeto

Prever churn de clientes com alta sensibilidade (recall) e precis√£o suficiente para que a equipe de reten√ß√£o:

1. Concentre esfor√ßos nos casos de maior risco.
2. Minimize desperd√≠cio de recursos em falsos alarmes.

---

## üîç 3. Entendimento e Inicia√ß√£o

### 3.1 Escolha do Dataset

* **Fonte**: [Telco Customer Churn (Kaggle)](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
* **Conte√∫do**:

  * Dados demogr√°ficos (g√™nero, idade, dependentes)
  * Tipo de contrato (`Contract`), m√©todo de pagamento
  * Uso de servi√ßos (TV, internet, suporte t√©cnico)
  * M√©tricas de consumo (`MonthlyCharges`, `TotalCharges`)
  * Flag `Churn` (‚ÄúYes‚Äù/‚ÄúNo‚Äù)

### 3.2 Perguntas de Neg√≥cio

* Quais atributos realmente influenciam a decis√£o de churn?
* Como limpar inconsist√™ncias (e.g., `TotalCharges` como texto, espa√ßos vazios)?
* Em um dataset desbalanceado (\~27% churn), como priorizar a detec√ß√£o de churners sem gerar alarmes falsos em excesso?

### 3.3 Respostas √†s Perguntas de Neg√≥cio

1. **Atributos que influenciam o churn**
   Concentrei-me em extrair `feature_importances_` do Random Forest e apresentei um gr√°fico/tabela com os 10 atributos mais significativos.
2. **Limpeza de inconsist√™ncias**

   * Convertemos `TotalCharges` de string para num√©rico:

     ```python
     df['TotalCharges'] = pd.to_numeric(df['TotalCharges'].str.strip().replace('', np.nan), errors='coerce').fillna(0)
     ```
   * Imputei valores faltantes em categ√≥ricas com `'Unknown'` e em num√©ricas com a mediana.
   * Removi identificadores (`customerID`) e verifiquei duplicatas.
3. **Tratamento do desbalanceamento**

   * Utilizei SMOTETomek para gerar churners sint√©ticos e remover exemplos amb√≠guos.
   * Otimizei o threshold via F‚ÇÇ‚ÄëScore (Œ≤=2) para maximizar recall sem Explodir falsos positivos.

---

## üßº 4. Limpeza e Prepara√ß√£o dos Dados

### 4.1 Remo√ß√£o de Identificadores

* Descartei `customerID` por n√£o agregar valor preditivo.

### 4.2 Convers√£o de `TotalCharges`

* Detectei espa√ßos e strings vazias:

  ```python
  df['TotalCharges'].sample(10)
  ```
* Apliquei a fun√ß√£o de convers√£o (descrita acima) para evitar erros no pipeline.

### 4.3 Imputa√ß√£o de Valores Faltantes

* **Categ√≥ricas**: preenchi com `'Unknown'`.
* **Num√©ricas**: preenchi com a mediana.
  Verifica√ß√£o final:

```python
print(df.isnull().sum())  # Todos os valores nulos zerados
```

### 4.4 Checagem de Duplicatas e Tipos

```python
print(df.duplicated().sum())  # ‚Üí 0 duplicatas
print(df.dtypes)             # ‚Üí tipos adequados
```

Insight: dados bem limpos evitam vazamentos e erros de convers√£o no pipeline.

---

## üìä 5. Engenharia de Features

### 5.1 Features Base

| Feature                  | Como Criada                                             | Porqu√™                                                                   |
| ------------------------ | ------------------------------------------------------- | ------------------------------------------------------------------------ |
| tenure\_group            | `pd.cut(df.tenure, bins=[0,6,12,24,60,72], labels=[‚Ä¶])` | Captura padr√µes n√£o lineares de risco em diferentes dura√ß√µes do contrato |
| avg\_charge\_per\_tenure | `df['TotalCharges'] / df['tenure'].replace(0,1)`        | Normaliza o gasto total pelo tempo de perman√™ncia                        |
| high\_value\_flag        | `(MonthlyCharges > Q3) & (tenure > median)`             | Detecta clientes de alto valor propensos a churn precoce                 |
| service\_density         | Soma de ‚ÄúYes‚Äù em colunas de servi√ßos extras             | Clientes com poucos servi√ßos extras apresentam churn mais r√°pido         |

### 5.2 Features Derivadas da An√°lise de Erro

Durante a an√°lise de erros (v2), observei padr√µes em falsos negativos (FNs) e falsos positivos (FPs):

```python
# False Negatives
fn_mask = (y_test==1) & (y_pred==0)
print(X_test[fn_mask][['Contract','PaymentMethod','MonthlyCharges','tenure']].describe())

# False Positives
fp_mask = (y_test==0) & (y_pred==1)
print(X_test[fp_mask][['Contract','PaymentMethod','MonthlyCharges','tenure']].describe())
```

**Padr√µes Detectados:**

* **FN** (churn n√£o previsto): altas cobran√ßas iniciais, tenure baixo, contrato mensal.
* **FP** (alarme falso): pagamento autom√°tico, contratos anuais, m√∫ltiplos servi√ßos ativos.

**Novas Features Criadas**

| Feature              | Como Criada                                                                      | Porqu√™                                                                 |
| -------------------- | -------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| MonthlyCharges\_log  | `np.log1p(df['MonthlyCharges'])`                                                 | Reduz skew e enfatiza varia√ß√µes relativas em cobran√ßas altas           |
| SeniorContractCombo  | `(df.SeniorCitizen==1).astype(int) * df.Contract.map({'Month-to-month':1, ...})` | Captura risco elevado de clientes s√™niores em contratos menos est√°veis |
| SupportServicesCount | Soma de ‚ÄúYes‚Äù em servi√ßos de suporte                                             | Clientes sem suporte extra t√™m +35% de chance de churn                 |

### 5.3 Import√¢ncia dos Atributos

A seguir, o top‚Äë10 de features ordenadas pelo `feature_importances_` do Random Forest:

| Atributo                        | Import√¢ncia (%) |
| ------------------------------- | --------------- |
| Contract\_Month-to-month        | 17.43%          |
| Contract\_Two year              | 10.44%          |
| OnlineSecurity\_No              | 10.11%          |
| TechSupport\_No                 | 8.34%           |
| PaymentMethod\_Electronic check | 6.01%           |
| tenure                          | 5.63%           |
| InternetService\_Fiber optic    | 3.79%           |
| tenure\_group\_0-6              | 3.45%           |
| TotalCharges                    | 3.12%           |
| MonthlyCharges                  | 2.74%           |

---

## ‚öôÔ∏è 6. Pipeline de Machine Learning

### 6.1 Separa√ß√£o de Vari√°veis

```python
X = df.drop('Churn', axis=1)
y = df['Churn'].map({'Yes':1, 'No':0})
```

### 6.2 Pr√©-processamento com ColumnTransformer

**Num√©ricas**:

```python
('num', Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
]), numeric_features)
```

**Categ√≥ricas**:

```python
('cat', Pipeline([
    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
]), categorical_features)
```

### 6.3 Balanceamento de Classes com SMOTETomek

```python
from imblearn.combine import SMOTETomek
('smote', SMOTETomek(sampling_strategy=1.0, random_state=42))
```

**Por qu√™?** Gera churners sint√©ticos (SMOTE) e remove pontos amb√≠guos (Tomek Links), melhorando a separabilidade e reduzindo overfitting.

### 6.4 Classificador Random Forest

```python
('classifier', RandomForestClassifier(
    class_weight='balanced',
    random_state=42
))
```

### 6.5 Encadeamento em Pipeline

```python
pipeline = Pipeline([
    ('create_features', FunctionTransformer(create_features, validate=False)),
    ('preprocessor', preprocessor),
    ('smote', SMOTETomek(sampling_strategy=1.0, random_state=42)),
    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42))
])
```

Benef√≠cio: encapsula todo o fluxo, evita vazamento de dados e garante reprodutibilidade.

---

## üéØ 7. Tuning de Hiperpar√¢metros e F‚ÇÇ-Score

### 7.1 Motiva√ß√£o

KPI principal: capturar churners (recall) sem gerar custos elevados com falsos positivos.
M√©trica escolhida: F‚ÇÇ-Score (Œ≤=2), que penaliza mais fortemente os falsos negativos.

### 7.2 Configura√ß√£o do Scorer

```python
from sklearn.metrics import make_scorer, fbeta_score
f2_scorer = make_scorer(fbeta_score, beta=2)
```

### 7.3 RandomizedSearchCV

```python
search = RandomizedSearchCV(
    pipeline, param_dist, n_iter=40, cv=cv,
    scoring=f2_scorer, verbose=1, n_jobs=-1, random_state=42
)
search.fit(X_train, y_train)
best_model = search.best_estimator_
```

Resultado: recall > 90% na classe churn e precis√£o consistentemente melhorada.

---

## üéõÔ∏è 8. Threshold Din√¢mico & Classifica√ß√£o de Risco

### 8.1 C√°lculo do Threshold √ìtimo

```python
from sklearn.metrics import precision_recall_curve
prec, rec, thr = precision_recall_curve(y_test, y_probs)
f2_scores = (1 + 2**2) * (prec * rec) / (4 * prec + rec)
optimal_threshold = thr[np.nanargmax(f2_scores)]
```

### 8.2 Classifica√ß√£o de Risco

```python
def classify_risk(score):
    if score >= optimal_threshold + 0.25:
        return 'High'
    elif score >= optimal_threshold:
        return 'Moderate'
    else:
        return 'Low'
```

### 8.3 C√°lculo de Custo por Previs√£o

```python
df_result['PredictionType'] = np.select(
    [
        (df_result['True']==1) & (df_result['Pred']==0),
        (df_result['True']==0) & (df_result['Pred']==1)
    ],
    ['FN', 'FP'],
    default='TN/TP'
)
df_result['Cost'] = np.select(
    [df_result['PredictionType']=='FP', df_result['PredictionType']=='FN'],
    [100, 2000],
    default=0
)
```

---

## üìà 9. Resultados Finais

**Optimized Classification Report:**

| Classe           | Precision | Recall | F1-score | Support |
| ---------------- | --------- | ------ | -------- | ------- |
| 0                | 0.96      | 0.57   | 0.72     | 1053    |
| 1                | 0.42      | 0.93   | 0.58     | 352     |
| **accuracy**     |           |        | 0.66     | 1405    |
| **macro avg**    | 0.69      | 0.75   | 0.65     | 1405    |
| **weighted avg** | 0.82      | 0.66   | 0.68     | 1405    |

**Optimal Threshold**: 0.45
**Recall (Churn)**: 93% ‚Äî captura quase todos os churners.
**Precis√£o (Churn)**: 42% ‚Äî aceit√°vel dado o alto custo de perder um churner.

---

## üí° 10. Comparativo de Vers√µes

| Vers√£o | Acc  | Prec | Recall | F1   | F2   | AUC-ROC | Principais Mudan√ßas             |
| ------ | ---- | ---- | ------ | ---- | ---- | ------- | ------------------------------- |
| v1     | 0.79 | 0.71 | 0.45   | 0.55 | 0.49 | 0.80    | Modelo baseline                 |
| v2     | 0.83 | 0.61 | 0.90   | 0.73 | 0.75 | 0.83    | Threshold otimizado (PR curve)  |
| v3     | 0.83 | 0.42 | 0.93   | 0.58 | 0.66 | 0.83    | Ajustes de features e F2-tuning |

**Nota**: AUC-ROC ‚âà 0.83 confirma bom poder discriminativo, n√£o aleatoriedade.

---

## üìå 11. Conclus√£o Operacional e Pr√≥ximos Passos

Este modelo atinge alto recall com custo operacional baixo, gra√ßas ao uso de e-mails e mensagens automatizadas.

* **FNs** ficaram abaixo de 7%, evitando grandes perdas.
* **FPs** geram custo m√≠nimo e criam oportunidades de engajamento.
* A escolha do F‚ÇÇ-Score refor√ßa a prioridade de capturar churners.

### 11.1 Estrat√©gias de A√ß√£o para Clientes de Alto Risco

| Segmento   | Crit√©rio                | N¬∫ de Clientes | A√ß√£o                        |
| ---------- | ----------------------- | -------------- | --------------------------- |
| Cr√≠tico    | Prob. Churn ‚â• 80%       | 120            | Atendimento humano imediato |
| Alto Risco | 60% ‚â§ Prob. Churn < 80% | 300            | Campanhas personalizadas    |
| Monitorar  | 45% ‚â§ Prob. Churn < 60% | 500            | Engajamento preventivo      |

### 11.2 Kit de A√ß√µes por Segmento

* **üî¥ Cr√≠tico (Prob. ‚â• 80%)**: contato humano em at√© 24h, oferta VIP (desconto + upgrade), visita t√©cnica preventiva. *Meta: ‚â• 65% de taxa de convers√£o.*
* **üü† Alto Risco (60%‚Äì80%)**: e-mail segmentado, refor√ßo via SMS. *Meta: ‚â• 45% de abertura/intera√ß√£o.*
* **üü¢ Monitorar (45%‚Äì60%)**: comunica√ß√£o autom√°tica (e-mail/SMS gen√©rico), promo√ß√µes leves (cr√©dito extra, gamifica√ß√£o). *Meta: ‚â• 25% de resposta.*

### 11.3 C√°lculo de Custo-Benef√≠cio e ROI

| Item                 | Custo Unit√°rio | Reten√ß√£o Estimada |
| -------------------- | -------------- | ----------------- |
| Liga√ß√£o VIP          | R\$ 150        | 70%               |
| E-mail Personalizado | R\$ 10         | 40%               |
| SMS                  | R\$ 2          | 15%               |

```text
custo_total = (120 * 150) + (300 * 10) + (500 * 2) = R$ 24.000
receita_preservada = (120*0.7 + 300*0.4 + 500*0.15) * 2500 = R$ 1.162.500
ROI = (1.162.500 - 24.000) / 24.000 ‚âà 4743%
```

### 11.4 Fluxo de Governan√ßa

* **Di√°rio**: atualizar lista de clientes cr√≠ticos √†s 8h.
* **Semanal**: reuni√£o de an√°lise de convers√µes com equipe de CX.
* **Mensal**: ajustar limites de probabilidade conforme capacidade e testar novas mensagens/ofertas com A/B testing.

### 11.5 Alertas Proativos (Exemplo)

```python
if prob_churn >= 0.8 and contract == "Monthly" and support_tickets >= 3:
    enviar_para_fila("URGENTE", cliente_id)
elif prob_churn >= 0.6 and internet_service == "Fiber":
    oferecer_upgrade_gratis(cliente_id)
```

### 11.6 Resultados Esperados

* Redu√ß√£o de 25‚Äì30% no churn nos segmentos Cr√≠tico e Alto Risco.
* ROI de 10:1 para cada real investido em reten√ß√£o.
* Aumento de 15% no NPS devido a a√ß√µes personalizadas.
